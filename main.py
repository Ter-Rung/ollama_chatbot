# from fastapi import FastAPI, Form
# from chain import RAGEngine

# app = FastAPI()
# rag = RAGEngine()

# @app.get("/")
# def root():
#     return {"message": "Welcome to the SuperWAL RAG chatbot üöÄ"}

# @app.post("/ask")
# def ask_question(question: str = Form(...)):
#     answer = rag.ask(question)
#     return {"question": question, "answer": answer}

from fastapi import FastAPI, Form, Request
from fastapi.responses import StreamingResponse, JSONResponse
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_ollama import OllamaLLM, OllamaEmbeddings
from langchain.prompts import PromptTemplate
# from starlette.concurrency import run_in_threadpool
from langchain_community.vectorstores import FAISS
from fastapi.concurrency import run_in_threadpool
import os
import asyncio
import time

app = FastAPI()

# from langchain.chains import LLMChain
# from langchain.chains.question_answering import load_qa_chain

prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh. D·ª±a tr√™n n·ªôi dung sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn, ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß.

N·ªôi dung:
{context}

C√¢u h·ªèi:
{question}
"""
)


# Kh·ªüi t·∫°o RAG ch·ªâ 1 l·∫ßn
class RAGEngine:
    def __init__(self, data_folder="./data"):
        self.data_folder = data_folder
        self.llm = OllamaLLM(model="mistral", temperature=0.2, streaming=True) 
        self.embeddings = OllamaEmbeddings(model="mistral")
        self.retriever = self._load_data()
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.retriever,
            chain_type_kwargs={"prompt": prompt_template},
            return_source_documents=False
        )



    def _load_data(self):
        index_path = os.path.join(self.data_folder, "faiss_index")
        if os.path.exists(index_path):
            return FAISS.load_local(
                index_path,
                self.embeddings,
                allow_dangerous_deserialization=True
            ).as_retriever(search_kwargs={"k": 3})
        
        docs = []
        for filename in os.listdir(self.data_folder):
            if filename.endswith(".txt"):
                loader = TextLoader(os.path.join(self.data_folder, filename))
                docs.extend(loader.load())

        text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        texts = text_splitter.split_documents(docs)
        db = FAISS.from_documents(texts, self.embeddings)
        db.save_local(index_path)
        return db.as_retriever(search_kwargs={"k": 3})

    def run_sync(self, question: str) -> str:
        return self.qa_chain.run(question)



    async def ask(self, question: str) -> str:
        try:
            # Ch·∫°y LLM trong threadpool ƒë·ªÉ kh√¥ng block event loop, gi·ªõi h·∫°n timeout 15s
            result = await asyncio.wait_for(
                run_in_threadpool(self.run_sync, question),
                timeout=150
            )
            return result
        except asyncio.TimeoutError:
            return "‚è±Ô∏è Xin l·ªói, h·ªá th·ªëng ph·∫£n h·ªìi ch·∫≠m. Vui l√≤ng th·ª≠ l·∫°i sau."
        except Exception as e:
            # Log l·ªói chi ti·∫øt n·∫øu c·∫ßn
            print(f"‚ùå L·ªói khi g·ªçi LLM: {e}")
            return "‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i sau."

# Kh·ªüi t·∫°o 1 instance duy nh·∫•t
rag = RAGEngine()

@app.get("/")
def root():
    return {"message": "Welcome to the SuperWAL RAG chatbot üöÄ"}

@app.post("/ask")
async def ask_question(question: str = Form(...)):
    answer = await rag.ask(question)
    return {"question": question, "answer": answer}

@app.post("/chat-stream")
async def chat_stream(request: Request):
    try:
        # üëá Gi·∫£ s·ª≠ client g·ª≠i d·∫°ng JSON
        data = await request.json()
        question = data.get("question", "")

        async def generate():
            yield "ü§î ƒêang x·ª≠ l√Ω...\n\n"
            await asyncio.sleep(0.5)
            answer = await rag.ask(question)
            for chunk in answer.split():
                yield chunk + " "
                await asyncio.sleep(0.05)

        return StreamingResponse(generate(), media_type="text/plain")

    except Exception as e:
        async def error_stream():
            yield "‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i sau."
        return StreamingResponse(error_stream(), media_type="text/plain")

@app.get("/health")
def health():
    return {"status": "ok", "model": "mistral", "backend": "Ollama"}
